{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a3485c1-3616-49a6-a541-5246c576e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.onnxruntime import ORTModelForQuestionAnswering, ORTModelForAudioClassification, ORTModelForSequenceClassification, ORTModelForSpeechSeq2Seq\n",
    "from transformers import AutoConfig, Wav2Vec2Processor, AutoTokenizer, PretrainedConfig, WhisperProcessor\n",
    "import time\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import audio_base \n",
    "import metric\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17346e07-e69a-452c-8907-11095b3ac412",
   "metadata": {},
   "source": [
    "# Речь в текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a668ac-1ed8-42fd-96e6-32224e0865be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are using a model of type whisper to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Слушай, я потратил обретьом кучу денег для того, чтобы притоситься в эту дару. Это что вообще такое? Посмотри на официантов, они все в черных каких-то рубашках с кислыми минами. Даже никто из них до сих пор не подошел к нам.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sampling_rate =  16000\n",
    "path_a ='01_happiness_anger a_020.wav'\n",
    "speech, sr = librosa.load(path_a, sr=sampling_rate)\n",
    "model_text = audio_base.SpeechtoText('whisper-tiny_onnx', \"openai/whisper-base\", \"openai/whisper-tiny\")\n",
    "model_text.run(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "add289d5-94c7-4842-b0ba-7aebff4a4e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'angry'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_a ='01_happiness_anger a_020.wav'\n",
    "speech, sr = librosa.load(path_a, sr=sampling_rate)\n",
    "model_em = audio_base.SpeechtoEmotion(\"wav2vec2-xls-r-300m-emotion-ru_onnx\", \"KELONMYOSA/wav2vec2-xls-r-300m-emotion-ru\")\n",
    "model_em.run(speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7049a-2787-4aab-9a38-3fe41eebb7bb",
   "metadata": {},
   "source": [
    "# Текст в эмоции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88aa544-086e-4036-8bf4-2cc54e9f9a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_textem = audio_base.TexttoEmotion(\"rubert-tiny2-russian-emotion-detection_onnx\", \"Djacon/rubert-tiny2-russian-emotion-detection\")\n",
    "model_textem.run(\"ой беда, какая беда\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b5a6d2-77e0-4505-91a9-fa8c3b88452b",
   "metadata": {},
   "source": [
    "## Общий поток распознавания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa031db-bf41-44ce-bc8a-b7ea195496c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "You are using a model of type whisper to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n",
      "Ignored unknown kwarg option normalize\n"
     ]
    }
   ],
   "source": [
    "path_a ='01_happiness_anger a_020.wav'\n",
    "# path_a = '1725.wav'\n",
    "\n",
    "\n",
    "# создаем модели\n",
    "\n",
    "model_text = audio_base.SpeechtoText(config.model_name_speech_to_text[0], config.model_name_speech_to_text[1], config.model_name_speech_to_text[2])\n",
    "model_textem = audio_base.TexttoEmotion(config.model_name_text_to_emo[0], config.model_name_text_to_emo[1])\n",
    "model_em = audio_base.SpeechtoEmotion(config.model_name_speech_to_emo[0],config.model_name_speech_to_emo[1],)\n",
    "\n",
    "# длина эпизода записи в с. \n",
    "dt = 1\n",
    "d = 16000 * dt\n",
    "n_d = 4\n",
    "\n",
    "\n",
    "# rez_text_all = model_text.run(speech)\n",
    "# rez_text_all_buf = rez_text_all[0] \n",
    "# rez_text_all_list = rez_text_all[0].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba851f1-75d2-4d10-9126-a05dcc492762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' Слушай, потратил об этом  кучу денег для  того, что  притащится в эту дару. Это что   вообще такое? Посмотри на офицантов. Они все в    черных каких-то рубашках с   кислыми минами. Даже   никто из них до сих пор не  подошел к нам.',\n",
       "      t                                         sub_string        word  \\\n",
       " 0  0.0   Слушай, потратил об этом кучу денег. Для того...     Слушай,   \n",
       " 1  0.5   кучу денег для того, чтобы притащиться в эту ...        кучу   \n",
       " 2  1.0   Для того, что притащится в эту дару, это что ...       того,   \n",
       " 3  1.5   что притащится в эту дару. Это что вообще так...  притащится   \n",
       " 4  2.0   В эту дару это что вообще такое посовинайся ц...      вообще   \n",
       " \n",
       "           em1    em2  emotion  k2  k1  \n",
       " 0     neutral  angry     0.50  26   0  \n",
       " 1     neutral  angry     0.50  16   0  \n",
       " 2     neutral  angry     0.50  15   4  \n",
       " 3  enthusiasm  angry     0.55  36   4  \n",
       " 4  enthusiasm  angry     0.55  20  19  )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, df =  audio_base.check_model(path_a, dt=1, d=d, n_d=4,  model_text=model_text, model_textem=model_textem, model_em=model_em)\n",
    "s, df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5053f48-620c-497c-8c62-c78bf4b77ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Слушай, потратил об этом  кучу денег для  того, что  притащится в эту дару. Это что   вообще такое? Посмотри на офицантов. Они все в    черных каких-то рубашках с   кислыми минами. Даже   никто из них до сих пор не  подошел к нам.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42db914-9667-4007-95ff-4ea71826467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_rez = 'save_rez/'\n",
    "\n",
    "df.to_csv(dir_rez + '.'.join(path_a.split('/')[-1].split('.')[:-1]) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc8da9af-7075-49ed-aaf7-51d339124447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_resd = '../dataset/RESD_csv/'\n",
    "\n",
    "dir_rez = 'save_rez/'\n",
    "\n",
    "df_test = pd.read_csv(dir_resd + 'test.csv')\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5fa89a6-1686-4f6d-ba20-9e73707c05e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger', 'disgust', 'enthusiasm', 'fear', 'happiness', 'neutral', 'sadness'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_test.emotion.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f0d1e60-6e25-4d6b-804c-727269348650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 16:55:47.458179040 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.0/conv/Conv' Status Message: Invalid input shape: {7}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 16:56:20.654958616 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.6/conv/Conv' Status Message: Invalid input shape: {1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 16:56:22.348949748 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.6/conv/Conv' Status Message: Invalid input shape: {1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n",
      "....no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 16:57:05.295286508 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.6/conv/Conv' Status Message: Invalid input shape: {1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 16:57:09.407816276 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.5/conv/Conv' Status Message: Invalid input shape: {1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n",
      "........no audio or no convert\n",
      "error\n",
      "...no audio or no convert\n",
      "error\n",
      "...no audio or no convert\n",
      "error\n",
      ".......no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n",
      "....no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "......no audio or no convert\n",
      "error\n",
      "...................no audio or no convert\n",
      "error\n",
      "...no audio or no convert\n",
      "error\n",
      "...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 17:02:44.547086212 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.0/conv/Conv' Status Message: Invalid input shape: {9}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "..no audio or no convert\n",
      "error\n",
      "..no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "......no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "....no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "..no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 17:04:58.515300231 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.5/conv/Conv' Status Message: Invalid input shape: {1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n",
      "...no audio or no convert\n",
      "error\n",
      "....no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n",
      ".....................no audio or no convert\n",
      "error\n",
      ".........no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n",
      "..no audio or no convert\n",
      "error\n",
      "....no audio or no convert\n",
      "error\n",
      "......no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "........no audio or no convert\n",
      "error\n",
      "....no audio or no convert\n",
      "error\n",
      "..no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "........................no audio or no convert\n",
      "error\n",
      "....no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n",
      "......no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "..no audio or no convert\n",
      "error\n",
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 17:14:59.175003497 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.6/conv/Conv' Status Message: Invalid input shape: {1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n",
      "..no audio or no convert\n",
      "error\n",
      ".no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "......."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 17:16:09.407100684 [E:onnxruntime:, sequential_executor.cc:514 ExecuteKernel] Non-zero status code returned while running Conv node. Name:'/wav2vec2/feature_extractor/conv_layers.3/conv/Conv' Status Message: Invalid input shape: {2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no audio or no convert\n",
      "error\n",
      "...no audio or no convert\n",
      "error\n",
      "no audio or no convert\n",
      "error\n",
      "..."
     ]
    }
   ],
   "source": [
    "result =  []\n",
    "for i in range(df_test.shape[0]):\n",
    "        \n",
    "    try:\n",
    "        path_a = dir_resd + 'test/' +df_test.iloc[i,1]\n",
    "        text = df_test.iloc[i,3]\n",
    "        emotion = df_test.iloc[i,2]\n",
    "        s, df =  audio_base.check_model(path_a, dt=1, d=d, n_d=4,  model_text=model_text, model_textem=model_textem, model_em=model_em)\n",
    "        met = metric.calculate_wer(text, s)\n",
    "        rez_emo = df.iloc[:,5].mean()\n",
    "        \n",
    "        df.to_csv(dir_rez + '.'.join(path_a.split('/')[-1].split('.')[:-1]) + '.csv')\n",
    "        result.append([ i, path_a, text, s, emotion, rez_emo, met])\n",
    "        print(end='.')    \n",
    "    except: \n",
    "        print('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cda27f-83ed-4171-a42d-4f771ab6ec90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6434af5e-56c8-45f1-bb23-3f9a338703e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "6 columns passed, passed data had 7 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 6 columns passed, passed data had 7 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_true\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext_recognize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43memo_true\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwer_analis_resd.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:806\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 806\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    815\u001b[0m         arrays,\n\u001b[1;32m    816\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    819\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    820\u001b[0m     )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 6 columns passed, passed data had 7 columns"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(result, columns= ['No', 'name','text_true', 'text_recognize', 'emo_true', 'met' ]).to_csv('wer_analis_resd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8112ae2c-9fef-4019-8340-39d2b1b9d136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c74f2372-7178-4f17-b340-2d97e1ddcef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting language_tool_python\n",
      "  Downloading language_tool_python-2.8.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pip in /home/boss/.local/lib/python3.10/site-packages (from language_tool_python) (24.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from language_tool_python) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/boss/.local/lib/python3.10/site-packages (from language_tool_python) (4.66.1)\n",
      "Requirement already satisfied: wheel in /home/boss/.local/lib/python3.10/site-packages (from language_tool_python) (0.38.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->language_tool_python) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->language_tool_python) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->language_tool_python) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->language_tool_python) (2020.6.20)\n",
      "Downloading language_tool_python-2.8.1-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: language_tool_python\n",
      "Successfully installed language_tool_python-2.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install language_tool_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040cdce2-1b33-4d25-b088-cc3030aaaf54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:23<00:00, 10.6MB/s]\n",
      "Unzipping /tmp/tmphv7f_nak.zip to /home/boss/.cache/language_tool_python.\n",
      "Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to /home/boss/.cache/language_tool_python.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match({'ruleId': 'MORFOLOGIK_RULE_RU_RU', 'message': 'Возможно найдена орфографическая ошибка.', 'replacements': ['Проверка'], 'offsetInContext': 0, 'context': 'Проверкка текста на ашибки.', 'offset': 0, 'errorLength': 9, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Проверкка текста на ашибки.'}), Match({'ruleId': 'MORFOLOGIK_RULE_RU_RU', 'message': 'Возможно найдена орфографическая ошибка.', 'replacements': ['ошибке', 'ошибки', 'ошибка', 'ашики', 'ошейке', 'ошейки', 'ошибку', 'сшибке', 'сшибки', 'ушебти', 'ушиби', 'ушибли', 'ушивке', 'ушивки', 'шибки', 'а шибки'], 'offsetInContext': 20, 'context': 'Проверкка текста на ашибки.', 'offset': 20, 'errorLength': 6, 'category': 'TYPOS', 'ruleIssueType': 'misspelling', 'sentence': 'Проверкка текста на ашибки.'})]\n"
     ]
    }
   ],
   "source": [
    "import language_tool_python\n",
    "\n",
    "tool = language_tool_python.LanguageTool('ru-RU')\n",
    "text = 'Проверкка текста на ашибки.'\n",
    "matches = tool.check(text)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe3403f-186d-4924-889b-79c03fcdf7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/boss/.local/lib/python3.10/site-packages (3.9.1)\n",
      "Collecting pymorphy2\n",
      "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: click in /home/boss/.local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/boss/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/boss/.local/lib/python3.10/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /home/boss/.local/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
      "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
      "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: docopt>=0.6 in /home/boss/.local/lib/python3.10/site-packages (from pymorphy2) (0.6.2)\n",
      "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
      "Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
      "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
      "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "424ed93f-6c65-4d51-ac70-3242eb971575",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/boss/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/boss/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/boss/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to /home/boss/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/boss/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/boss/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/boss/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pymorphy2\n",
    "\n",
    "# загружаем словари и правила для pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# загружаем русский язык для NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('words')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72170ec7-1879-4e3c-a0b5-4472ad0296fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "проверкк текст на ашибкий\n"
     ]
    }
   ],
   "source": [
    "# извлекаем текст из PDF-файла\n",
    "text = 'Проверкка текста на ашибки.'\n",
    "\n",
    "# токенизируем текст и удаляем пунктуацию\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tokens = [word for word in tokens if word.isalnum()]\n",
    "\n",
    "# исправляем орфографические ошибки\n",
    "corrected_tokens = []\n",
    "for token in tokens:\n",
    "    parsed_token = morph.parse(token)[0]\n",
    "    corrected_tokens.append(parsed_token.normal_form)\n",
    "   \n",
    "# восстанавливаем пунктуацию\n",
    "final_text = \"\"\n",
    "for i, token in enumerate(corrected_tokens):\n",
    "    final_text += token\n",
    "    if i < len(corrected_tokens) - 1 and corrected_tokens[i+1] not in string.punctuation:\n",
    "        final_text += \" \"\n",
    "    elif i < len(corrected_tokens) - 1 and corrected_tokens[i+1] in string.punctuation:\n",
    "        final_text += corrected_tokens[i+1]\n",
    "\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7e84501-69ed-49fb-ab8f-4230786bd071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parse(word='ашибки', tag=OpencorporaTag('ADJS,Qual plur'), normal_form='ашибкий', score=0.5714285714285714, methods_stack=((DictionaryAnalyzer(), 'шибки', 11, 30), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'а')))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4615764e-b655-45f8-af32-ffd08dc9adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspellchecker in /home/boss/.local/lib/python3.10/site-packages (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91767c55-2a74-45cc-a112-81ae779c180d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "текст\n",
      "{'теста', 'текст'}\n",
      "проверка\n",
      "{'проверка'}\n",
      "ошибки\n",
      "{'ошибки'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from spellchecker import SpellChecker\n",
    " \n",
    "spell = SpellChecker(language='ru', distance=2)\n",
    " \n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(text.split(' '))\n",
    " \n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    " \n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00292402-2637-42dc-8312-c238faddf09f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
